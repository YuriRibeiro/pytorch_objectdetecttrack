{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Tracking\n",
    "\n",
    "Detector: Multi Class Pre Trained YOLO v3\n",
    "\n",
    "Rastreador: SORT (Simple, online, real-time detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\linear_assignment_.py:22: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Importar Bibliotecas\n",
    "from models import *\n",
    "from utils import *\n",
    "\n",
    "import os, sys, time, datetime, random, shutil, glob\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "from IPython.display import clear_output\n",
    "from sort import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "config_path  = 'config/yolov3.cfg'\n",
    "weights_path = 'config/yolov3.weights'\n",
    "class_path   = 'config/coco.names'\n",
    "img_size     = 416\n",
    "conf_thres   = 0.8\n",
    "nms_thres    = 0.4\n",
    "\n",
    "# Load model and weights\n",
    "model = Darknet(config_path, img_size=img_size)\n",
    "model.load_weights(weights_path)\n",
    "model.eval()\n",
    "classes = utils.load_classes(class_path)\n",
    "Tensor  = torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_image(img):\n",
    "    # scale and pad image\n",
    "    ratio = min(img_size/img.size[0], img_size/img.size[1])\n",
    "    imw = round(img.size[0] * ratio)\n",
    "    imh = round(img.size[1] * ratio)\n",
    "    img_transforms = transforms.Compose([ transforms.Resize((imh, imw)),\n",
    "         transforms.Pad((max(int((imh-imw)/2),0), max(int((imw-imh)/2),0), max(int((imh-imw)/2),0), max(int((imw-imh)/2),0)),\n",
    "                        (128,128,128)),\n",
    "         transforms.ToTensor(),\n",
    "         ])\n",
    "    # convert image to Tensor\n",
    "    image_tensor = img_transforms(img).float()\n",
    "    image_tensor = image_tensor.unsqueeze_(0)\n",
    "    input_img = Variable(image_tensor.type(Tensor))\n",
    "    # run inference on the model and get detections\n",
    "    with torch.no_grad():\n",
    "        detections = model(input_img)\n",
    "        detections = utils.non_max_suppression(detections, 80, conf_thres, nms_thres)\n",
    "    return detections[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\n",
      "Directory  object-detection-video-production_ID_3694423_1280x720_approx30fps.mp4  Created \n",
      "Começo do processamento:  12:09:32 \n",
      "\n",
      "Total de Frames do Vídeo:  1905.0\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\1.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\linear_assignment_.py:128: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\2.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\3.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\4.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\5.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\6.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\7.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\8.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\9.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\10.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\11.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\12.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\13.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\14.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\15.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\16.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\17.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\18.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\19.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\20.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\21.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\22.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\23.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\24.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\25.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\26.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\27.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\28.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\29.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\30.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\31.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\32.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\33.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\34.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\35.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\36.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\37.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\38.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\39.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\40.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\41.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\42.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\43.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\44.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\45.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\46.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\47.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\48.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\49.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\50.jpg\n",
      ".\\object-detection-video-production_ID_3694423_1280x720_approx30fps\\51.jpg\n",
      "Fim do Processamento:  12:11:50\n"
     ]
    }
   ],
   "source": [
    "def analisar_video(folderpath, filename):\n",
    "    global resulting_video_path\n",
    "    videopath = folderpath+filename\n",
    "    dirName = \"object-detection-video-\"+filename\n",
    "    resulting_video_path = \".\\\\\" + dirName[:-4]\n",
    "    print(resulting_video_path)\n",
    "    \n",
    "    if not os.path.exists(resulting_video_path):\n",
    "        os.mkdir(resulting_video_path)\n",
    "        print(\"Directory \" , dirName ,  \" Created \")\n",
    "    else:\n",
    "        shutil.rmtree(resulting_video_path)\n",
    "        os.mkdir(resulting_video_path)\n",
    "        print(\"Directory \" , dirName ,  \" Created \")\n",
    "        #print(\"Directory \" , dirName ,  \" already exists\")\n",
    "    \n",
    "    cmap = plt.get_cmap('tab20b')\n",
    "    colors = [cmap(i)[:3] for i in np.linspace(0, 1, 20)]\n",
    "\n",
    "    # initialize Sort object and video capture\n",
    "    vid         = cv2.VideoCapture(videopath)\n",
    "    mot_tracker = Sort() \n",
    "    \n",
    "    now = datetime.datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Começo do processamento: \", current_time, \"\\n\")\n",
    "    \n",
    "    # Video Properties\n",
    "    vid_time_milisseconds = 0\n",
    "    vid_total_frames = vid.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    print(\"Total de Frames do Vídeo: \", vid_total_frames)\n",
    "    \n",
    "    frame_atual = 0\n",
    "    while(True):\n",
    "        vid.set(cv2.CAP_PROP_POS_MSEC, vid_time_milisseconds)\n",
    "        vid_time_milisseconds += 100\n",
    "        succes_reading_video, frame = vid.read()\n",
    "        \n",
    "        if not succes_reading_video or frame_atual > 50:\n",
    "            now = datetime.datetime.now()\n",
    "            current_time = now.strftime(\"%H:%M:%S\")\n",
    "            print(\"Fim do Processamento: \", current_time)\n",
    "            break\n",
    "\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame_atual += 1\n",
    "        pilimg = Image.fromarray(frame)\n",
    "        detections = detect_image(pilimg)\n",
    "\n",
    "        img = np.array(pilimg)\n",
    "        pad_x = max(img.shape[0] - img.shape[1], 0) * (img_size / max(img.shape))\n",
    "        pad_y = max(img.shape[1] - img.shape[0], 0) * (img_size / max(img.shape))\n",
    "        unpad_h = img_size - pad_y\n",
    "        unpad_w = img_size - pad_x\n",
    "        if detections is not None:\n",
    "            tracked_objects = mot_tracker.update(detections.cpu())\n",
    "\n",
    "            unique_labels = detections[:, -1].cpu().unique()\n",
    "            n_cls_preds = len(unique_labels)\n",
    "            for x1, y1, x2, y2, obj_id, cls_pred in tracked_objects:\n",
    "                box_h = int(((y2 - y1) / unpad_h) * img.shape[0])\n",
    "                box_w = int(((x2 - x1) / unpad_w) * img.shape[1])\n",
    "                y1 = int(((y1 - pad_y // 2) / unpad_h) * img.shape[0])\n",
    "                x1 = int(((x1 - pad_x // 2) / unpad_w) * img.shape[1])\n",
    "\n",
    "                color = colors[int(obj_id) % len(colors)]\n",
    "                color = [i * 255 for i in color]\n",
    "                cls = classes[int(cls_pred)]\n",
    "                cv2.rectangle(frame, (x1, y1), (x1+box_w, y1+box_h), color, 4)\n",
    "                cv2.rectangle(frame, (x1, y1-35), (x1+len(cls)*19+60, y1), color, -1)\n",
    "                cv2.putText(frame, cls + \"-\" + str(int(obj_id)), (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 3)\n",
    "        print(resulting_video_path+\"\\\\\"+str(frame_atual)+str(\".jpg\"))\n",
    "        cv2.imwrite(resulting_video_path+\"\\\\\"+str(frame_atual)+str(\".jpg\"), frame)\n",
    "        #fig = plt.figure(figsize=(15, 15))\n",
    "        #ax = fig.add_subplot(1, 1, 1)\n",
    "        #ax.set_title(\"Video Stream\")\n",
    "        #ax.imshow(frame)\n",
    "        #plt.show()\n",
    "        #clear_output(wait=True)\n",
    "    return resulting_video_path\n",
    "\n",
    "folder_path = r'C:\\Users\\Ribeiro\\Google Drive\\Mestrado\\Dissertação\\Vídeos\\\\'\n",
    "videopath   = r'production_ID_3694423_1280x720_approx30fps.mp4'\n",
    "\n",
    "resulting_video_path = analisar_video(folder_path,videopath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar Vídeo Na Nova Pasta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
